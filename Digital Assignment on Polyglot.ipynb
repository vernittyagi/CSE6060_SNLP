{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name : Vernit Tyagi ::: Reg. No: 19MAI0010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the polyglot\n",
    "import polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Language detector is spectacular feature in polyglot, \n",
    "    it can detect the language(/s) in the text along with there\n",
    "    confidence value which provide us with strong glimpse for amount \n",
    "    of each language present in the text''' \n",
    "\n",
    "from polyglot.detect import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the hindi text taken from a news agency \"BBC HINDI\" https://www.bbc.com/hindi/india-53130113\n",
    "hindi_text = \"\"\"मुंबई में आर्थिक मामलों के विशेषज्ञ रघुवीर मुखर्जी कहते हैं, \"ये दुर्भाग्यपूर्ण है. \n",
    "चीन के साथ सीमा विवाद के मद्देनज़र उठाए जाने वाले क़दमों से भारत में फार्मा, \n",
    "मोबाइल फ़ोन और सौर ऊर्जा जैसे क्षेत्रों में अड़चनें पैदा हो सकती हैं\n",
    "वे कहते हैं, \"हिमालय के दोनों तरफ़ होने वाले व्यापार को पूरी तरह से रोकने की वकालत करना गैर-ज़िम्मेदाराना बात है, \n",
    "ख़ास तौर से ऐसे समय में जब दोनों तरफ़ के नेता स्थिति को शांत करने और इसे अधिक बिगड़ने से रोकने के लिए काफ़ी प्रयास कर रहे हैं.\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मुंबई में आर्थिक मामलों के विशेषज्ञ रघुवीर मुखर्जी कहते हैं, \"ये दुर्भाग्यपूर्ण है. \n",
      "चीन के साथ सीमा विवाद के मद्देनज़र उठाए जाने वाले क़दमों से भारत में फार्मा, \n",
      "मोबाइल फ़ोन और सौर ऊर्जा जैसे क्षेत्रों में अड़चनें पैदा हो सकती हैं\n",
      "वे कहते हैं, \"हिमालय के दोनों तरफ़ होने वाले व्यापार को पूरी तरह से रोकने की वकालत करना गैर-ज़िम्मेदाराना बात है, \n",
      "ख़ास तौर से ऐसे समय में जब दोनों तरफ़ के नेता स्थिति को शांत करने और इसे अधिक बिगड़ने से रोकने के लिए काफ़ी प्रयास कर रहे हैं.\n"
     ]
    }
   ],
   "source": [
    "print(hindi_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the object of the Detector and invoking on the hindi_text\n",
    "my_detector = Detector(hindi_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Hindi       code: hi       confidence:  99.0 read bytes:   895\n"
     ]
    }
   ],
   "source": [
    "#The below statement prints the language used in the hindi_text above along with the confidence value\n",
    "print(my_detector.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are taking a text which contains English,Hindi,Russian languages to detect all of the three\n",
    "text = \"\"\"There has been a news of India - China conflict in an hindi newspaper, it was like - मुंबई में आर्थिक मामलों के विशेषज्ञ रघुवीर मुखर्जी कहते हैं, \"ये दुर्भाग्यपूर्ण है. \n",
    "चीन के साथ सीमा विवाद के मद्देनज़र उठाए जाने वाले क़दमों से भारत में फार्मा, \n",
    "मोबाइल फ़ोन और सौर ऊर्जा जैसे क्षेत्रों में अड़चनें पैदा हो सकती हैं\n",
    "वे कहते हैं, \"हिमालय के दोनों तरफ़ होने वाले व्यापार को पूरी तरह से रोकने की वकालत करना गैर-ज़िम्मेदाराना बात है, \n",
    "ख़ास तौर से ऐसे समय में जब दोनों तरफ़ के नेता स्थिति को शांत करने और इसे अधिक बिगड़ने से रोकने के लिए काफ़ी प्रयास कर रहे हैं.\n",
    "По сообщению информационного агентства Reuters, правительство Индии подготовило список из 300 \n",
    "таких импортируемых товаров, которые рассматриваются с целью повышения тарифов.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There has been a news of India - China conflict in an hindi newspaper, it was like - मुंबई में आर्थिक मामलों के विशेषज्ञ रघुवीर मुखर्जी कहते हैं, \"ये दुर्भाग्यपूर्ण है. \n",
      "चीन के साथ सीमा विवाद के मद्देनज़र उठाए जाने वाले क़दमों से भारत में फार्मा, \n",
      "मोबाइल फ़ोन और सौर ऊर्जा जैसे क्षेत्रों में अड़चनें पैदा हो सकती हैं\n",
      "वे कहते हैं, \"हिमालय के दोनों तरफ़ होने वाले व्यापार को पूरी तरह से रोकने की वकालत करना गैर-ज़िम्मेदाराना बात है, \n",
      "ख़ास तौर से ऐसे समय में जब दोनों तरफ़ के नेता स्थिति को शांत करने और इसे अधिक बिगड़ने से रोकने के लिए काफ़ी प्रयास कर रहे हैं.\n",
      "По сообщению информационного агентства Reuters, правительство Индии подготовило список из 300 \n",
      "таких импортируемых товаров, которые рассматриваются с целью повышения тарифов.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Hindi       code: hi       confidence:  75.0 read bytes:   895\n",
      "name: Russian     code: ru       confidence:  19.0 read bytes:   880\n",
      "name: English     code: en       confidence:   5.0 read bytes:  1245\n"
     ]
    }
   ],
   "source": [
    "for language in Detector(text).languages:\n",
    "    print(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, above we have seen that the detector was successful in detecting all the three languages and it can help us to conclude that 75% is Hindi, 19% is Russian and 5% of the text is English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''So till now in our classes we have seen tokenization in nltk \n",
    "    here we will explore the tokenization in polyglot'''\n",
    "#So following is the text in russian taken from \"BBC News Russian\"\n",
    "raw = \"\"\"Авторы агитационной кампании сделали наибольший упор на теме семьи и детей. \n",
    "Даже на плакатах, которые призывают голосовать за доступную медицину или ежегодную индексацию пенсий,\n",
    "помещают фотографию младенца или ребенка, обнимающего бабушку.\n",
    "С баннеров об ответственном отношении к животным, которое тоже пропишут в Конституции,\n",
    "смотрят дети, обнимающие собаку или кошку.\n",
    "Нашумевший вирусный ролик агентства ФАН про геев, \n",
    "забирающих мальчика из детдома в 2035 году, тоже обращается к теме семьи и детей.\n",
    "На видео, опубликованном в начале июня, россиян пугают тем, \n",
    "что если не проголосовать за поправки, детей из приютов усыновят гей-пары.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Авторы агитационной кампании сделали наибольший упор на теме семьи и детей. \n",
      "Даже на плакатах, которые призывают голосовать за доступную медицину или ежегодную индексацию пенсий,\n",
      "помещают фотографию младенца или ребенка, обнимающего бабушку.\n",
      "С баннеров об ответственном отношении к животным, которое тоже пропишут в Конституции,\n",
      "смотрят дети, обнимающие собаку или кошку.\n",
      "Нашумевший вирусный ролик агентства ФАН про геев, \n",
      "забирающих мальчика из детдома в 2035 году, тоже обращается к теме семьи и детей.\n",
      "На видео, опубликованном в начале июня, россиян пугают тем, \n",
      "что если не проголосовать за поправки, детей из приютов усыновят гей-пары.\n"
     ]
    }
   ],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Авторы', 'агитационной', 'кампании', 'сделали', 'наибольший', 'упор', 'на', 'теме', 'семьи', 'и', 'детей', '.', 'Даже', 'на', 'плакатах', ',', 'которые', 'призывают', 'голосовать', 'за', 'доступную', 'медицину', 'или', 'ежегодную', 'индексацию', 'пенсий', ',', 'помещают', 'фотографию', 'младенца', 'или', 'ребенка', ',', 'обнимающего', 'бабушку', '.', 'С', 'баннеров', 'об', 'ответственном', 'отношении', 'к', 'животным', ',', 'которое', 'тоже', 'пропишут', 'в', 'Конституции', ',', 'смотрят', 'дети', ',', 'обнимающие', 'собаку', 'или', 'кошку', '.', 'Нашумевший', 'вирусный', 'ролик', 'агентства', 'ФАН', 'про', 'геев', ',', 'забирающих', 'мальчика', 'из', 'детдома', 'в', '2035', 'году', ',', 'тоже', 'обращается', 'к', 'теме', 'семьи', 'и', 'детей', '.', 'На', 'видео', ',', 'опубликованном', 'в', 'начале', 'июня', ',', 'россиян', 'пугают', 'тем', ',', 'что', 'если', 'не', 'проголосовать', 'за', 'поправки', ',', 'детей', 'из', 'приютов', 'усыновят', 'гей', '-', 'пары', '.'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''So here we are creating an object of Text, so that later we can invoke the tokenizer'''\n",
    "Text(raw).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> So as we have seen above here the tokenizer created the WordList automatically and the significant observation which I can infer from this is that the code is also very robust as compared to nltk as we have to import package tokenizer then we have to specify/import which tokenizer we have to use for an instance like word_tokenizer or sent_tokenizer and later we have to invoke those on the text but here we have to invoke just \".words\" or \".sentences\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The article is taken from CNN-Politics\n",
    "\n",
    "news_trump = \"\"\"The President's poor example represents a typical effort to divide Americans and highlight divisions over specific issues for his own political gain. But in the long run, apart from putting thousands of lives at risk, it is counterproductive, since a more stringent effort to avoid rises in infections as states open up would likely promote the fast economic recovery on which Trump is banking a reelection campaign that has slipped into trouble in recent weeks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President's poor example represents a typical effort to divide Americans and highlight divisions over specific issues for his own political gain. But in the long run, apart from putting thousands of lives at risk, it is counterproductive, since a more stringent effort to avoid rises in infections as states open up would likely promote the fast economic recovery on which Trump is banking a reelection campaign that has slipped into trouble in recent weeks.\n"
     ]
    }
   ],
   "source": [
    "print(news_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the polyglot downloader \n",
    "from polyglot.downloader import downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.en to\n",
      "[polyglot_data]     /home/varen/polyglot_data...\n",
      "[polyglot_data] Downloading package pos2.en to\n",
      "[polyglot_data]     /home/varen/polyglot_data...\n"
     ]
    }
   ],
   "source": [
    "#Now we are downloading the required models for pos_tagging\n",
    "%%bash\n",
    "polyglot download embeddings2.en pos2.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " (\"President's\", 'NUM'),\n",
       " ('poor', 'ADJ'),\n",
       " ('example', 'NOUN'),\n",
       " ('represents', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('typical', 'ADJ'),\n",
       " ('effort', 'NOUN'),\n",
       " ('to', 'PART'),\n",
       " ('divide', 'VERB'),\n",
       " ('Americans', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('highlight', 'VERB'),\n",
       " ('divisions', 'NOUN'),\n",
       " ('over', 'ADP'),\n",
       " ('specific', 'ADJ'),\n",
       " ('issues', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('own', 'ADJ'),\n",
       " ('political', 'ADJ'),\n",
       " ('gain', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('But', 'CONJ'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('long', 'ADJ'),\n",
       " ('run', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('apart', 'ADV'),\n",
       " ('from', 'ADP'),\n",
       " ('putting', 'VERB'),\n",
       " ('thousands', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('lives', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('risk', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('it', 'PRON'),\n",
       " ('is', 'VERB'),\n",
       " ('counterproductive', 'ADJ'),\n",
       " (',', 'PUNCT'),\n",
       " ('since', 'SCONJ'),\n",
       " ('a', 'DET'),\n",
       " ('more', 'ADV'),\n",
       " ('stringent', 'ADJ'),\n",
       " ('effort', 'NOUN'),\n",
       " ('to', 'PART'),\n",
       " ('avoid', 'VERB'),\n",
       " ('rises', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('infections', 'NOUN'),\n",
       " ('as', 'SCONJ'),\n",
       " ('states', 'NOUN'),\n",
       " ('open', 'VERB'),\n",
       " ('up', 'ADP'),\n",
       " ('would', 'AUX'),\n",
       " ('likely', 'ADV'),\n",
       " ('promote', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('fast', 'ADJ'),\n",
       " ('economic', 'ADJ'),\n",
       " ('recovery', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('Trump', 'PROPN'),\n",
       " ('is', 'VERB'),\n",
       " ('banking', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('reelection', 'NOUN'),\n",
       " ('campaign', 'NOUN'),\n",
       " ('that', 'DET'),\n",
       " ('has', 'AUX'),\n",
       " ('slipped', 'VERB'),\n",
       " ('into', 'ADP'),\n",
       " ('trouble', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('recent', 'ADJ'),\n",
       " ('weeks', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text function performs the tagging on words and '.pos_tags' gives the tagged words \n",
    "Text(news_trump).pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> So, we need necessary models in polyglot for the tasks like pos_tagging, morphological analysis etc., necessary models are downloaded and then can be invoked later with simple tokenizer function 'Text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package morph2.en to\n",
      "[polyglot_data]     /home/varen/polyglot_data...\n",
      "[polyglot_data] Downloading package morph2.ar to\n",
      "[polyglot_data]     /home/varen/polyglot_data...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "polyglot download morph2.en morph2.ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.text import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanging ['Hang', 'ing']\n",
      "sleeping ['sleep', 'ing']\n",
      "counting ['count', 'ing']\n",
      "checked ['check', 'ed']\n",
      "finalized ['final', 'ized']\n"
     ]
    }
   ],
   "source": [
    "word_list = [\"Hanging\",\"sleeping\",\"counting\",\"checked\",\"finalized\"]\n",
    "for i in word_list:\n",
    "    i = Word(i,language = \"en\")\n",
    "    print(i,i.morphemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-->Above we have seen that if the words are tokenized properly we can get the morphemes of the words clearly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################### SENTIMENT ANALYSIS #########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-->Sentiment analysis with polyglot can be performed by the help of the polarity of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_view = \"\"\"I watched House of Cards yesterday, I think it is the best web series till now on U.S politics.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched House of Cards yesterday, I think it is the best web series till now on U.S politics.\n"
     ]
    }
   ],
   "source": [
    "print(my_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package sentiment2.en to\n",
      "[polyglot_data]     /home/varen/polyglot_data...\n"
     ]
    }
   ],
   "source": [
    "#Downloading the sentiment package for english sentimental analysis\n",
    "%%bash\n",
    "polyglot download sentiment2.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Polarity\n",
      "----------------\n",
      "I 0\n",
      "watched 0\n",
      "House 0\n",
      "of 0\n",
      "Cards 0\n",
      "yesterday 0\n",
      ", 0\n",
      "I 0\n",
      "think 0\n",
      "it 0\n",
      "is 0\n",
      "the 0\n",
      "best 1\n",
      "web 0\n",
      "series 0\n",
      "till 0\n",
      "now 0\n",
      "on 0\n",
      "U.S 0\n",
      "politics 0\n",
      ". 0\n"
     ]
    }
   ],
   "source": [
    "#Printing each word and it's polarity\n",
    "'''\n",
    "'+1'--> positive words\n",
    "'-1'--> negative words\n",
    " '0'--> neutral words\n",
    "'''\n",
    "print(\"Word\",\"Polarity\")\n",
    "print(\"----------------\")\n",
    "for i in Text(my_view).words:\n",
    "    print(i,i.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Above we have seen Sentiment Analysis for a single sentence on the basis of polarity of each word, but it is really not a cakewalk if there is huge text so in this case entities in the text are recognized and sentiment analysis is done for an entity as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_sents = (\"Vernit watched a web series on last friday and gave a review about it.\"\n",
    "            \"According to his review the web series is best on politics.\")\n",
    "sent_text = Text(two_sents) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vernit watched a web series on last friday and gave a review about it.According to his review the web series is best on politics.\n"
     ]
    }
   ],
   "source": [
    "#Sentences splitted according to the entity\n",
    "sent_first = sent_text.sentences[0]\n",
    "print(sent_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package ner2.en to\n",
      "[polyglot_data]     /home/varen/polyglot_data...\n"
     ]
    }
   ],
   "source": [
    "#Importing the ner2 package which helps in the identification of the entities within the text\n",
    "%%bash\n",
    "polyglot download ner2.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vernit']\n"
     ]
    }
   ],
   "source": [
    "#Identifying and printing the entity in the above text\n",
    "entity_one= sent_first.entities[0]\n",
    "print(entity_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positive sentiment in the text\n",
    "entity_one.positive_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative sentiment in the text\n",
    "entity_one.negative_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
